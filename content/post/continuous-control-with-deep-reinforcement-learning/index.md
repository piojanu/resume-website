---
title: 'Continuous Control With Deep Reinforcement Learning'
summary: This time I want to explore how deep reinforcement learning can be utilized e.g. making a humanoid model walk. This kind of task is a continuous control task. A solution to such a task differs from the one you might know and use to play Atari games, like Pong, with e.g. Deep Q-Network (DQN). I’ll talk about what characterizes continuous control environments. Then, I’ll introduce the actor-critic architecture to you and show the example of the state-of-the-art actor-critic method, Soft Actor-Critic (SAC). Finally, we will dive into the code.
authors:
- piojanu
tags:
- Deep Reinforcement Learning
- Continuous Control 
- MuJoCo
- Humanoid
- Soft Actor-Critic
- SAC
date: "2021-10-14"
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Placement options: 1 = Full column width, 2 = Out-set, 3 = Screen-width
# Focal point options: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight
image:
  placement: 2
  caption: 'Image credit: [**Neptune.ai**](https://neptune.ai/blog/continuous-control-with-deep-reinforcement-learning)'
  focal_point: ""
  preview_only: true
  
external_link: "https://neptune.ai/blog/continuous-control-with-deep-reinforcement-learning"
---

Read the text on Neptune.ai Blog: [click here](https://neptune.ai/blog/continuous-control-with-deep-reinforcement-learning).
